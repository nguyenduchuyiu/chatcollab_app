# core/behavior_executor.py
import time
import random
import threading
import json
import traceback
import re # Import regex for parsing
from typing import TYPE_CHECKING, Dict, Any, List

from flask import Flask
from services.llm_service import LLMService # Added
from utils.helpers import parse_output

if TYPE_CHECKING:
    from core.interaction_coordinator import InteractionCoordinator
    from core.agent_manager import AgentManager # Import for type hinting

CLASSMATE_SPEAK_PROMPT = """
## Role & Context
B·∫°n l√† {AI_name}, m·ªôt ng∆∞·ªùi b·∫°n tham gia th·∫£o lu·∫≠n To√°n.
Vai tr√≤ c·ª• th·ªÉ: {AI_role}
M·ª•c ti√™u ch√≠nh c·ªßa b·∫°n: {AI_goal}
B·ªëi c·∫£nh: {AI_backstory}
NƒÉng l·ª±c/Ch·ª©c nƒÉng c·ªßa b·∫°n trong nh√≥m: {AI_tasks}

## Goal for this Turn
D·ª±a tr√™n suy nghƒ© n·ªôi t√¢m **hi·ªán t·∫°i** c·ªßa b·∫°n (`{inner_thought}`), h√£y t·∫°o ra c√¢u n√≥i ti·∫øp theo cho {AI_name} trong cu·ªôc th·∫£o lu·∫≠n nh√≥m. C√¢u n√≥i n√†y ph·∫£i t·ª± nhi√™n, ph√π h·ª£p v·ªõi vai tr√≤, b·ªëi c·∫£nh, v√† tu√¢n th·ªß c√°c h∆∞·ªõng d·∫´n v·ªÅ h√†nh vi giao ti·∫øp.

## Inputs You Receive
*   **B√†i to√°n:** {problem}
*   **T√™n b·∫°n b√®:** {friends}
*   **Nhi·ªám v·ª•/M·ª•c ti√™u Giai ƒëo·∫°n Hi·ªán t·∫°i:** {current_stage_description} (Quan tr·ªçng ƒë·ªÉ x√°c ƒë·ªãnh STEP#id)
*   **Suy nghƒ© N·ªôi t√¢m Hi·ªán t·∫°i c·ªßa B·∫°n:** {inner_thought} (ƒê√¢y l√† **kim ch·ªâ nam** cho n·ªôi dung v√† √Ω ƒë·ªãnh c√¢u n√≥i c·ªßa b·∫°n)
*   **L·ªãch s·ª≠ H·ªôi tho·∫°i:** {history} (ƒê·ªÉ hi·ªÉu ng·ªØ c·∫£nh g·∫ßn nh·∫•t)

## Process to Generate Your Response
1.  **Ph√¢n t√≠ch Suy nghƒ© N·ªôi t√¢m (`{inner_thought}`):** X√°c ƒë·ªãnh r√µ l√Ω do b·∫°n mu·ªën n√≥i, √Ω ƒë·ªãnh ch√≠nh (h·ªèi, tr·∫£ l·ªùi, ƒë·ªÅ xu·∫•t, l√†m r√µ, v.v.), v√† ƒë·ªëi t∆∞·ª£ng b·∫°n mu·ªën t∆∞∆°ng t√°c (m·ªôt ng∆∞·ªùi c·ª• th·ªÉ, c·∫£ nh√≥m).
2.  **X√°c ƒë·ªãnh Nhi·ªám v·ª• Hi·ªán t·∫°i:** D·ª±a v√†o `{current_stage_description}` v√† `{history}`, x√°c ƒë·ªãnh ch√≠nh x√°c nhi·ªám v·ª• (v√≠ d·ª•: `STEP#1`, `STEP#2`) m√† nh√≥m ƒëang th·ª±c hi·ªán.
3.  **So·∫°n th·∫£o L·ªùi n√≥i:** K·∫øt h·ª£p th√¥ng tin t·ª´ b∆∞·ªõc 1 v√† 2 ƒë·ªÉ vi·∫øt c√¢u n√≥i c·ªßa b·∫°n, tu√¢n th·ªß c√°c H√†nh vi Giao ti·∫øp b√™n d∆∞·ªõi.
4.  **Chu·∫©n b·ªã JSON Output:** T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng JSON ch·ª©a suy nghƒ© chu·∫©n b·ªã (`internal_thought`) v√† l·ªùi n√≥i cu·ªëi c√πng (`spoken_message`).

## Behavior Guidelines (QUAN TR·ªåNG)
*   **T·ª± nhi√™n & S√∫c t√≠ch:** N√≥i ng·∫Øn g·ªçn nh∆∞ trong tr√≤ chuy·ªán th·ª±c t·∫ø. Tr√°nh vƒÉn vi·∫øt, l√Ω thuy·∫øt d√†i d√≤ng.
*   **Tr√°nh L·∫∑p l·∫°i:** Kh√¥ng nh·∫Øc l·∫°i y nguy√™n ƒëi·ªÅu ng∆∞·ªùi kh√°c v·ª´a n√≥i.
*   **H·∫°n ch·∫ø C√¢u h·ªèi Cu·ªëi c√¢u:** ƒê·ª´ng *lu√¥n lu√¥n* k·∫øt th√∫c b·∫±ng c√¢u h·ªèi "?".
*   **ƒêa d·∫°ng H√†nh ƒë·ªông N√≥i:** Linh ho·∫°t s·ª≠ d·ª•ng c√°c ki·ªÉu n√≥i kh√°c nhau.
*   **M·ªôt H√†nh ƒë·ªông Ch√≠nh/L∆∞·ª£t:** T·∫≠p trung v√†o M·ªòT h√†nh ƒë·ªông ng√¥n ng·ªØ ch√≠nh.
*   **T·∫≠p trung v√†o Nhi·ªám v·ª• Hi·ªán t·∫°i:** B√°m s√°t m·ª•c ti√™u c·ªßa STEP# hi·ªán t·∫°i. KH√îNG n√≥i tr∆∞·ªõc c√°c b∆∞·ªõc sau.
*   **T∆∞∆°ng t√°c C√° nh√¢n (N·∫øu ph√π h·ª£p):** C√¢n nh·∫Øc d√πng t√™n b·∫°n b√® n·∫øu h·ª£p l√Ω.

## Output Format
**Y√äU C·∫¶U TUY·ªÜT ƒê·ªêI:** 
    1. Ch·ªâ tr·∫£ v·ªÅ M·ªòT ƒë·ªëi t∆∞·ª£ng JSON DUY NH·∫§T ch·ª©a hai kh√≥a sau. KH√îNG th√™m b·∫•t k·ª≥ gi·∫£i th√≠ch hay vƒÉn b·∫£n n√†o kh√°c b√™n ngo√†i ƒë·ªëi t∆∞·ª£ng JSON. 
    2. KH√îNG ch·ª©a CON#/STEP#/FUNC#, tin nh·∫Øn ph·∫£i t·ª± nhi√™n.
    3. M·ªçi bi·ªÉu th·ª©c to√°n h·ªçc, tabular ƒë·ªÅu in ra d·∫°ng latex v√† ƒë·ªÉ trong d·∫•u '$' v√≠ d·ª• $x^2$, nh·ªõ escape c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát.
    4. ƒê·ªãnh d·∫°ng tin nh·∫Øn trong c√°c html block.
{{
  "spoken_message": "<N·ªôi dung c√¢u n√≥i cu·ªëi c√πng, t·ª± nhi√™n, c√≥ th·ªÉ in h√¨nh minh h·ªça (v√≠ d·ª• b·∫£ng bi·∫øn thi√™n, h√¨nh h·ªçc) ƒë·ªÉ gi√∫p m·ªçi ng∆∞·ªùi d·ªÖ h√¨nh dung>"
}}
V√≠ d·ª• JSON Output ƒê√öNG:
{{
  "spoken_message": "Ch√†o A, m√¨nh nghƒ© b∆∞·ªõc ƒë·∫ßu ti√™n l√† t√¨m t·∫≠p x√°c ƒë·ªãnh ƒë√∫ng kh√¥ng?"
}}
{{
  "spoken_message": "ƒê√∫ng r·ªìi B, c√°ch l√†m ƒë√≥ h·ª£p l√Ω ƒë√≥. D√πng ƒë·∫°o h√†m ƒë·ªÉ x√©t t√≠nh ƒë∆°n ƒëi·ªáu l√† chu·∫©n r·ªìi."
}}
V√≠ d·ª• JSON Output SAI (Kh√¥ng ƒë∆∞·ª£c l·ªô CON#/STEP# trong spoken_message):
{{
  "spoken_message": "ƒê√∫ng r·ªìi B, c√°ch l√†m c·ªßa b·∫°n ·ªü CON#4 l√† h·ª£p l√Ω ƒë√≥. D√πng ƒë·∫°o h√†m ƒë·ªÉ x√©t t√≠nh ƒë∆°n ƒëi·ªáu l√† chu·∫©n r·ªìi."
}}
"""

class BehaviorExecutor:
    def __init__(self,
                 interaction_coordinator: 'InteractionCoordinator',
                 problem_description: str,
                 llm_service: LLMService,
                 agent_manager: 'AgentManager',
                 app_instance: Flask):
        self.interaction_coordinator = interaction_coordinator
        self.problem = problem_description
        self._original_llm_service_input = llm_service # Store original input
        self.agent_manager = agent_manager
        self.app = app_instance # Store app instance

    # Helper to handle potential tuple issue
    def _get_llm_service(self) -> LLMService:
        if isinstance(self._original_llm_service_input, tuple):
            print("!!! WARN [BehaviorExecutor]: LLM Service was passed as a tuple, unpacking.")
            return self._original_llm_service_input[0]
        elif isinstance(self._original_llm_service_input, LLMService):
            return self._original_llm_service_input
        else:
            raise TypeError(f"Unexpected type for LLM service: {type(self._original_llm_service_input)}")

    def _format_history_for_prompt(self, history: List[Dict], count=15) -> str:
        recent_history = history[-count:]
        lines = []
        for i, event in enumerate(recent_history):
             text = event.get('content', {}).get('text', '(Non-message event)')
             source_display = event.get('content', {}).get('sender_name', event.get('source', 'Unknown'))
             lines.append(f"CON#{i+1} {source_display}: {text}")
        return "\n".join(lines) if lines else "Ch∆∞a c√≥ h·ªôi tho·∫°i."

    def _generate_final_message(self, session_id: str, agent_id: str, agent_name: str, thought_details: Dict, phase_context: Dict, history: List[Dict]) -> str:
        """Generates the final spoken message using the CLASSMATE_SPEAK prompt (JSON output)."""
        log_prefix = f"--- BEHAVIOR_EXECUTOR [{agent_name} - {session_id}]"
        print(f"{log_prefix}: Generating final message...")

        agent_mind = self.agent_manager.get_agent_mind(agent_id)
        if not agent_mind: return "(L·ªói: Kh√¥ng t√¨m th·∫•y th√¥ng tin agent)"
        persona = agent_mind.persona

        # Format phase description
        phase_desc_prompt = f"Stage {phase_context.get('id', 'N/A')}: {phase_context.get('name', 'Kh√¥ng r√µ')}\n"
        phase_desc_prompt += f"Description: {phase_context.get('description', 'Kh√¥ng c√≥ m√¥ t·∫£')}\n"
        tasks_list = phase_context.get('tasks', [])
        phase_desc_prompt += "Tasks:\n" + ("\n".join([f"- {t}" for t in tasks_list]) + "\n" if tasks_list else "(Kh√¥ng c√≥ nhi·ªám v·ª• c·ª• th·ªÉ cho giai ƒëo·∫°n n√†y)\n")
        goals_list = phase_context.get('goals', [])
        phase_desc_prompt += "Goals:\n" + ("\n".join([f"- {g}" for g in goals_list]) + "\n" if goals_list else "(Kh√¥ng c√≥ m·ª•c ti√™u c·ª• th·ªÉ cho giai ƒëo·∫°n n√†y)\n")

        # Get friend names
        all_agent_minds = self.agent_manager.agents.values()
        friend_names = [mind.persona.name for mind in all_agent_minds if mind.persona.agent_id != agent_id]
        user_name = "User"
        for event in reversed(history):
             if event['source'].startswith('user-') and 'sender_name' in event['content']:
                  user_name = event['content']['sender_name']; break
        if user_name not in friend_names: friend_names.append(user_name)

        prompt = CLASSMATE_SPEAK_PROMPT.format(
            AI_name=agent_name,
            AI_role=persona.role, AI_goal=persona.goal, AI_backstory=persona.backstory, AI_tasks=persona.tasks,
            problem=self.problem, friends=", ".join(friend_names),
            current_stage_description=phase_desc_prompt.strip(),
            inner_thought=thought_details.get('thought', '(Suy nghƒ© b·ªã l·ªói)'),
            history=self._format_history_for_prompt(history)
        )

        try:
            llm_service_instance = self._get_llm_service() # Use helper
            raw_response = llm_service_instance.generate(prompt)
            print(f"{log_prefix}: Raw LLM Speak Response: {raw_response}")

            # Parse JSON
            try:
                final_message = parse_output(raw_response)
                if not final_message:
                    print(f"!!! WARN [{log_prefix}]: LLM returned empty 'spoken_message'.")
                    return ""
                return final_message
            except Exception as parse_err: # Catch JSONDecodeError and others
                print(f"!!! ERROR [{log_prefix}]: Failed to parse LLM JSON Speak response: {parse_err}")
                print(f"Raw response was: {raw_response}")
                return "..."

        except Exception as e:
            print(f"!!! ERROR [{log_prefix}]: Failed during final message generation LLM call: {e}")
            traceback.print_exc()
            return "ü§ì"

    def _simulate_typing_and_speak(self, session_id: str, agent_id: str, agent_name: str, thought_details: Dict, phase_context: Dict, history: List[Dict]):
        """Generates message, simulates typing, and posts the message for a session."""
        log_prefix = f"--- BEHAVIOR_EXECUTOR [{agent_name} - {session_id}]"
        app = self.app # Use stored app instance

        # Generate message (no context needed directly here)
        final_message = self._generate_final_message(session_id, agent_id, agent_name, thought_details, phase_context, history)

        if not final_message:
            self.interaction_coordinator.post_event_to_clients(session_id, "agent_status", agent_id, {"status": "idle", "agent_name": agent_name}, True)
            return

        # Post typing status
        self.interaction_coordinator.post_event_to_clients(session_id, "agent_status", agent_id, {"status": "typing", "agent_name": agent_name}, True)

        # Calculate delay
        min_delay, max_delay, delay_per_char = 0.5, 5.0, random.uniform(0.03, 0.07)
        typing_delay = min(max_delay, max(min_delay, len(final_message) * delay_per_char))
        print(f"{log_prefix}: Simulating typing delay: {typing_delay:.2f}s")
        time.sleep(typing_delay)

        # Wrap DB-accessing part in app_context
        with app.app_context():
            try:
                print(f"{log_prefix}: Executing 'speak' action with message: {final_message}")
                # This call triggers DB access via add_event
                self.interaction_coordinator.handle_internal_trigger(
                    session_id=session_id, event_type="new_message", source=agent_id,
                    content={"text": final_message, "sender_name": agent_name}
                )
            except Exception as e:
                print(f"!!! ERROR [{log_prefix}]: Failed during handle_internal_trigger: {e}")
                traceback.print_exc()

        # Post idle status
        self.interaction_coordinator.post_event_to_clients(session_id, "agent_status", agent_id, {"status": "idle", "agent_name": agent_name}, True)

    def execute(self, session_id: str, agent_id: str, agent_name: str, action: str, selected_thought_details: Dict, phase_context: Dict, history: List[Dict]):
        """Executes the selected action for the agent within a session."""
        log_prefix = f"--- BEHAVIOR_EXECUTOR [{agent_name} - {session_id}]"
        print(f"{log_prefix}: Received execution request - Action: {action}")

        # Post idle status helper
        def post_idle():
             self.interaction_coordinator.post_event_to_clients(
                 session_id, "agent_status", agent_id, {"status": "idle", "agent_name": agent_name}, True)

        if action == "speak":
            if not selected_thought_details:
                print(f"{log_prefix}: Error - 'speak' action requested without thought details. Skipping.")
                post_idle()
                return

            thread = threading.Thread(
                target=self._simulate_typing_and_speak,
                args=(session_id, agent_id, agent_name, selected_thought_details, phase_context, history),
                daemon=True
            )
            thread.start()

        elif action == "listen":
            print(f"{log_prefix}: Executing 'listen' action (no operation).")
            post_idle() # Set status to idle immediately
        else:
            print(f"{log_prefix}: Unknown action '{action}'.")
            post_idle() # Set status to idle for unknown actions